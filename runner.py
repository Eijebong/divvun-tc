"""
This script interprets a .json file generated by the decision task to run a set
of github actions. To prevent accidental leaks, it will first gather all
secrets the current task has access to from taskcluster to be able to filter
them on its output. It will then iterate over the actions defined in that file
and execute them while handling all of the mapped inputs/outputs as well as a
few environment variables necessary for github actions to work.

As for github actions "commands", this supports:
    - ::add-mask (`core.setSecret`) to add a secret value to hide in the logs.
    - ::set-output (`core.setOutput`) to set an output value from this task.
      Note that all output values will be put in a outputs.json artifacts from
      the task and can be referenced from another task. This is useful to pass
      values across tasks running on different runners. Outputs are also stored
      in the runner and can be reused as inputs in subsequent actions.
    - ::add-path (`core.addPath`) to add a path to the `PATH` environment
      variable. This works on all 3 OSes and values will also be added to
      subsequent actions.

We also support extensions to the github actions commands:
    - ::create-artifact (`process.stdout.write('::create-artifact path=setup.exe::path/to/exe')`
      This will immediately create a public artifact attached to the task.

The JSON format should look like this:

    ```
    { "action_name": {..action_description..}}
    ```

    - Action name is used to map input/outputs, it can be anything
    - Action description is an object described below
    Note that actions are ran in order they're defined in in the object.

Action description format:
    ```
    {
        "env": {"name": "value", ...},
        "inputs": {"name": "value", ...},
        "secret_inputs": {"name": {"secret": "tc-secret", "name": "foo"}, ...},
        "mapping": [{"input": "name", "from": {"task": "task_id", "action": "action_name", "output": "output_name}}, ...],
        "script": ""
    }
    ```
    - env: This should be dictionary containing environment variables to have
      while running the step. Note that this is action specific unlike the
      `::add-path` command.
    - inputs: static inputs to pass to the task. This will add
      `INPUT_{name.upper}` as an environment variable with the input value
      stringified. True/False will be stringified as "true"/"false".
    - secret_inputs: An object containing a name and a secret path description.
      Secrets in taskcluster are stored in a JSON object that you can get by
      name. That's what the `secret` key is for. Then we index that JSON with
      `name` and put the stringified value into `INPUT_{name.upper()}` just
      like a normal input.
    - mapping: This is to map an output from another task as an input for this
      one. It's a list of mapping object defined as this:
      - input: The name of the input the value will be put into.
      - from:
        - task: The takscluster task id to take outputs from
        - action_name: The action name from that task to get outputs from
        - output: The output name from that task to take the value from
    - script: The script to run. This is usually `node path/to/action.js` but could be anything.
"""

import sys
import asyncio
import codecs
import json
import os
import platform
import subprocess
import shutil

from collections import defaultdict
from typing import Set, Dict, List, Any
from taskcluster import helper

import utils

SECRETS: Set[str] = set()
OUTPUTS: defaultdict[str, Dict[str, str]] = defaultdict(lambda: {})
EXTRA_PATH: List[str] = []
_ORIG_PRINT = print


def filtered_print(*args):
    """
    This function is designed to replace the original print function to avoid
    accidental secret leaks. It'll replace all secrets contained in the
    `SECRETS` global variable with `[*******]`.
    """
    filtered = []
    for arg in args:
        for secret in SECRETS:
            arg = str(arg).replace(secret, "[******]")
        filtered.append(arg)
    _ORIG_PRINT(*filtered)


print = filtered_print


def gather_secrets():
    """
    Gather all available secrets from taskcluster and put them into the global
    `SECRETS` variable. This should be called quite early to avoid accidental
    secrets leaking.
    """
    secrets_service = helper.TaskclusterConfig().get_service("secrets")
    secret_names: Set[str] = set()

    def get_values_from_json(obj: Any) -> Set[str]:
        """
        Returns a list of values contained in a JSON object by recursively traversing it.
        """
        out = set()

        def flatten(x):
            if isinstance(x, dict):
                for value in x.values():
                    flatten(value)
            elif isinstance(x, list):
                for value in x:
                    flatten(value)
            else:
                out.add(x)

        flatten(obj)
        return out

    continuation = None
    while True:
        res = secrets_service.list(continuationToken=continuation)
        secret_names.update(set(res["secrets"]))
        if not res.get("continuationToken"):
            break
        continuation = res["continuationToken"]

    for name in secret_names:
        try:
            res = secrets_service.get(name)
            SECRETS.update(get_values_from_json(res["secret"]))
        except:
            # This happens when we're not allowed to read the secret. Unfortunately
            # there's no way of filtering out secrets we can't read from the
            # listing so we have to try to get them all.
            pass


async def process_command(step_name: str, line: str) -> bool:
    """
    Try processing a command from a github action.
    Return True to keep the line in the logs, False to hide it
    """

    if line.startswith("::add-mask::"):
        secret = line[len("::add-mask::") :]
        SECRETS.add(secret)
        return False

    if line.startswith("::set-output"):
        output = line[len("::set-output") :]
        name, value = output.split("::", 1)
        name = name.split("=")[1]
        OUTPUTS[step_name][name] = value
    elif line.startswith("::add-path::"):
        path = line[len("::add-path::") :]
        EXTRA_PATH.append(path)
    elif line.startswith("::create-artifact"):
        output = line[len("::create-artifact") :]
        name, path = output.split("::", 1)
        name = name.split("=")[1]
        with open(path, "rb") as fd:
            await utils.create_extra_artifact_async(name, fd.read(), public=True)

    return True


async def process_line(step_name: str, line: str):
    """
    Process a line from the task logs. This will check if it's a command or
    not, process that and then print the line on stdout. Note that since we've
    overridden the print command, secrets are filtered out
    """
    if line.startswith("::"):
        if not await process_command(step_name, line):
            return None

    print(line)


def get_env_for(step_name: str, step: Dict[str, Any]):
    """
    Return the environment for an action by combining the current environment
    (to forward taskcluster infos) and the `env`, `inputs`, `secret_inputs` and
    `mapping` fields from the description as well a few extra things either
    needed by our builders to behave properly or by github actions.
    """

    def to_string(value):
        if isinstance(value, bool):
            return "true" if value else "false"
        return value

    env = os.environ
    secrets_service = helper.TaskclusterConfig().get_service("secrets")
    for name, value in step["env"].items():
        env[name] = os.path.expandvars(value)
        os.environ = env

    for name, value in step["inputs"].items():
        env["INPUT_" + name.upper()] = os.path.expandvars(to_string(value))
        os.environ = env

    for input_name, secret in step["secret_inputs"].items():
        name = "INPUT_" + input_name.upper()
        res = secrets_service.get(secret["secret"])["secret"]
        parts = secret["name"].split('.')
        for part in parts:
            res = res[part]
        env[name] = to_string(res)

    for mapping in step["mapping"]:
        name = "INPUT_" + mapping["input"].upper()
        if mapping["task_id"]:
            with open(
                os.path.join(
                    os.environ["GITHUB_WORKSPACE"], mapping["task_id"] + ".json"
                )
            ) as fd:
                values = json.loads(fd.read())
            print(values)
            env[name] = values[mapping["from"]["action"]][mapping["from"]["output"]]
        else:
            env[name] = OUTPUTS[mapping["from"]["action"]][mapping["from"]["output"]]

    env["GITHUB_ACTION"] = step_name
    if platform.system() == "Darwin":
        # Macos builders don't run as root so the proxy listens on :8080 instead of :80
        env["TASKCLUSTER_PROXY_URL"] = "http://taskcluster:8080"
        env["PATH"] = env["PATH"] + ":/opt/homebrew/bin"
        env["LC_ALL"] = "en_US.UTF-8"
        env["LANG"] = "en_US.UTF-8"
    else:
        env["TASKCLUSTER_PROXY_URL"] = "http://taskcluster"
    env["BUILD_DIR"] = env["GITHUB_WORKSPACE"]

    if EXTRA_PATH:
        if platform.system() == "Windows":
            env["PATH"] = env["PATH"] + ";" + ";".join(EXTRA_PATH)
        else:
            env["PATH"] = env["PATH"] + ":" + ":".join(EXTRA_PATH)

    return env


def write_outputs():
    """
    Write the outputs from all actions that ran in our task. Those might be
    needed by other tasks. Note that those are private artifacts in case
    secrets creep up in them
    """
    utils.create_extra_artifact("outputs.json", json.dumps(OUTPUTS).encode())


async def run_action(action_name: str, action: Dict[str, Any]):
    env = get_env_for(action_name, action)

    extra_args = {}

    if platform.system() == 'Linux':
        # Ubuntu uses dash as its /bin/sh which breaks env variables with dashes in them
        extra_args['executable'] = '/bin/bash'

    process = await asyncio.subprocess.create_subprocess_shell(
        action["script"],
        env=env,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        **extra_args
    )
    assert process.stdout

    decoder = codecs.getincrementaldecoder("utf-8")(errors="replace")
    while True:
        line = await process.stdout.readline()
        if not line:
            break

        line_str = decoder.decode(line).strip().lstrip()
        await process_line(action_name, line_str)

    await process.wait()

    if process.returncode != 0:
        print(f"Process exited with code: {process.returncode}")
        raise SystemError()


async def main():
    gather_secrets()
    file = sys.argv[1]
    with open(file) as fd:
        actions = json.loads(fd.read())

    for name, action in actions.items():
        await run_action(name, action)


try:
    asyncio.run(main())
finally:
    # Cleanup on macos since it's the only runner not entirely stateless.
    if platform.system() == "Darwin":
        shutil.rmtree(os.environ["GITHUB_WORKSPACE"])

write_outputs()
